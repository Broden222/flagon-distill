{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83034970",
   "metadata": {},
   "source": [
    "# Distill Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809cd43",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49900c00",
   "metadata": {},
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54331ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright 2022 The Applied Research Laboratory for Intelligence and Security (ARLIS)\n",
    "#\n",
    "# Licensed to the Apache Software Foundation (ASF) under one or more\n",
    "# contributor license agreements.  See the NOTICE file distributed with\n",
    "# this work for additional information regarding copyright ownership.\n",
    "# The ASF licenses this file to You under the Apache License, Version 2.0\n",
    "# (the \"License\"); you may not use this file except in compliance with\n",
    "# the License.  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d170c5",
   "metadata": {},
   "source": [
    "### Imports Used in this Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2e506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import connections\n",
    "from elasticsearch_dsl import Search\n",
    "from elasticsearch_dsl import Q\n",
    "from elasticsearch_dsl.query import MultiMatch, Match\n",
    "from collections import Counter, deque\n",
    "from itertools import count\n",
    "from uuid import uuid4\n",
    "\n",
    "import distill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import hashlib, base64\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55f549a",
   "metadata": {},
   "source": [
    "## Define Search into Logging Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5359a48",
   "metadata": {},
   "source": [
    "Using Elasticsearch as a backend, we can create new connection to a test instance and define a search object based on that instance and a specific index to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8eed107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Elasticsearch([{'host': 'localhost', 'port': 9200}])>\n"
     ]
    }
   ],
   "source": [
    "flagonClient = connections.create_connection('flagonTest', hosts=['localhost:9200'], timeout=60)\n",
    "\n",
    "#TODO describeabs connections\n",
    "\n",
    "#hello world test\n",
    "print(flagonClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6caa6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "AleS = Search(using='flagonTest', index=\"userale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4b599",
   "metadata": {},
   "source": [
    "## Define Queries against Log Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c2b4ea",
   "metadata": {},
   "source": [
    "### Simple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85cbdaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bool(should=[Match(logType='raw'), Match(logType='custom')])\n"
     ]
    }
   ],
   "source": [
    "qLogType = Q(\"match\", logType=\"raw\") | Q(\"match\", logType=\"custom\")\n",
    "print(qLogType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3db4b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match(userId='superset-user')\n"
     ]
    }
   ],
   "source": [
    "qUserId = Q(\"match\", userId=\"superset-user\")\n",
    "print(qUserId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9fa6510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bool(must=[Match(sessionID=''), Match(sessionID='')])\n"
     ]
    }
   ],
   "source": [
    "qExcludeSession = Q(\"match\", sessionID=\"\") & Q(\"match\", sessionID=\"\")\n",
    "print(qExcludeSession)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f18d58",
   "metadata": {},
   "source": [
    "### Not-As-Simple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f94c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wildcard(pageUrl={'value': '*/superset/dashboard*'})\n"
     ]
    }
   ],
   "source": [
    "qUrl = Q({\"wildcard\": {\n",
    "    \"pageUrl\": {\n",
    "        \"value\": \"*/superset/dashboard*\"\n",
    "    }\n",
    "}})\n",
    "print(qUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3806738",
   "metadata": {},
   "source": [
    "### Define Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ae3df5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bool(filter=[Bool(must_not=[Terms(type=['keydown', 'mousedown', 'mouseup'])])])\n"
     ]
    }
   ],
   "source": [
    "filterEvents = Q('bool', filter=[~Q('terms', type=['keydown', 'mousedown', 'mouseup'])])\n",
    "print(filterEvents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218dcf93",
   "metadata": {},
   "source": [
    "## Chained Searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94521da8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afab6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "elk_search = AleS \\\n",
    "    .query(qUrl) \\\n",
    "    .query(qLogType) \\\n",
    "    .query(qUserId) \\\n",
    "    .query(filterEvents) \\\n",
    "    .extra(track_total_hits=True) #breaks return limit of 10000 hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9411a",
   "metadata": {},
   "source": [
    "NOTE: `.execute()` will only retreive the first 10 hits with additional terms embedded in queries. Use `.scan()` instead if you want to retreive all the hits. We use `.execute()` below for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7401817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11761\n"
     ]
    }
   ],
   "source": [
    "ale_dict = {}\n",
    "elk_response = elk_search.scan()\n",
    "for hit in elk_response:\n",
    "    logEntry = (hit.to_dict())\n",
    "    logEntry['uid'] = distill.getUUID(logEntry)\n",
    "    logEntry['clientTime'] = distill.epoch_to_datetime(logEntry['clientTime'])\n",
    "    ctr = len(ale_dict)\n",
    "    ctr += 1\n",
    "    ale_dict[ctr] = logEntry\n",
    "\n",
    "print(len(ale_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b761d6ca",
   "metadata": {},
   "source": [
    "## Data Forensics\n",
    "Data Forensics refers to ascertaining what is in our data. We may decide that we filtered to much or too little, and want to re-run our scan through ELK. Or, we may decide just how to apply filters as we go and \"carve\" out new dictionaries with less data, but more of the data we want. The following examples illustrate how to work with UserALE data in a dictionary format to perform data forensics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cd296d",
   "metadata": {},
   "source": [
    "### Sorting\n",
    "Getting User logs into a logical sequence can aid in a number of operations down the line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ba205d",
   "metadata": {},
   "source": [
    "A simple lambda function helps in sorting our user log dict by `clientTime` (when logs were written by the client)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be808aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11761"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data = dict(sorted(ale_dict.items(), key = lambda kv: kv[1]['clientTime']))\n",
    "len(sorted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d381225",
   "metadata": {},
   "source": [
    "### Searching\n",
    "Before we can filter out what we don't want in our data, we have to be able to be able to describe what we do and don't want.  Dictionaries are a fast and efficient way to search through data and Distill provides some supporting libraries for finding the information you want from your user logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e91341",
   "metadata": {},
   "source": [
    "Distill's `find_meta_values` function uses list comprehensions to quickly provide all the unique values for specific key (e.g., `sessionID`, `userId`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bae89caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['session_1642561069785',\n",
       " 'session_1642012917325',\n",
       " 'session_1640118177195',\n",
       " 'session_1642013755036',\n",
       " 'session_1641502434428',\n",
       " 'session_1641584276813',\n",
       " 'session_1642562635205',\n",
       " 'session_1641844965430',\n",
       " 'session_1640029398947',\n",
       " 'session_1642004982781',\n",
       " 'session_1640200820004']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions = distill.find_meta_values('sessionID', sorted_data)\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed519ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superset-user']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = distill.find_meta_values('userId', sorted_data)\n",
    "users "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3840bf",
   "metadata": {},
   "source": [
    "Relying on the dictionary format, we can quickly create new dictionaries with certain characteristics using simple dictionary comprehensions (e.g., a dictionary with all logs that contain the key: `path`; a dictionarey with all logs where `type`== `click`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76139d82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11758"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = ['path']\n",
    "sorted_data_paths = {k:v for k, v in sorted_data.items() if any(item in values for item in v.keys())}\n",
    "len(sorted_data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bf84749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = ['click']\n",
    "sorted_data_paths_clicks = {k:v for k, v in sorted_data_paths.items() if any(item in values for item in v.values())}\n",
    "len(sorted_data_paths_clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a86d61",
   "metadata": {},
   "source": [
    "Using the same methods, we can find all logs that refer to a specific DOM element in the field `path`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cbaf33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1883"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ele = ['div.superset-legacy-chart-world-map']\n",
    "sorted_data_pathele = {k:v for k, v in sorted_data_paths.items() if any(item in ele for item in v['path'])}\n",
    "len(sorted_data_pathele.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecac79e3",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "User data is always nested in time--the things they do, explore, and select are bound to time. Segmentation is the practice of slicing a series of data into a set of epochs (time-bound bins of logs) defined by some characteristic. They can be very general (e.g., 30 second, non-overlapping intervals starting from the beginning of a user session), or they can be very specific (e.g., an epoch when users were interacting with a specific UI element with filters set). Segmentation is generally very challenging and in the realm of 'advanced user analytics'--Distill makes segmentation much easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f867369",
   "metadata": {},
   "source": [
    "We want to to be able to create and curate segments without having to rewrite new datasets every time. We're going to start by creating a Master Dictionary for all our interesting segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10e34203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superSegments = {}\n",
    "superSegments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d991926",
   "metadata": {},
   "source": [
    "### Finding Deadspace\n",
    "One of the most simple ways of defining an epoch is that nothing is in it! We call this \"deadspace\"--a user might have started doing something else AFK, but we have no user behavior to indicate they've switch tasks (e.g., `blur` event). Deadspace can be useful to identify; we can omit it from other segments if we need to. Distill's `detect_deadspace` function is helpful for finding deadspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47553657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadSpace1 Segment_Type.DEADSPACE (1640029869288, 1640030063271) 193.983 4 [350, 301, 346, 347]\n",
      "deadSpace2 Segment_Type.DEADSPACE (1640030219069, 1640098958897) 68739.828 2 [840, 924]\n",
      "deadSpace3 Segment_Type.DEADSPACE (1640098969598, 1640099715182) 745.584 2 [991, 990]\n",
      "deadSpace4 Segment_Type.DEADSPACE (1640099716927, 1640118186776) 18469.849 3 [1007, 674, 1126]\n",
      "deadSpace5 Segment_Type.DEADSPACE (1640118296632, 1640182567282) 64270.65 6 [782, 981, 1121, 1222, 1227, 1241]\n",
      "deadSpace6 Segment_Type.DEADSPACE (1640182573419, 1640201030250) 18456.831 3 [1231, 1426, 1589]\n",
      "deadSpace7 Segment_Type.DEADSPACE (1640201075969, 1640201157009) 81.04 2 [1651, 1819]\n",
      "deadSpace8 Segment_Type.DEADSPACE (1640201172007, 1640201332691) 160.684 2 [1812, 1869]\n",
      "deadSpace9 Segment_Type.DEADSPACE (1640201346787, 1640201425011) 78.224 4 [1974, 2102, 2118, 2127]\n",
      "deadSpace10 Segment_Type.DEADSPACE (1640201494535, 1640201568436) 73.901 4 [2183, 2184, 2185, 2186]\n",
      "deadSpace11 Segment_Type.DEADSPACE (1640201578551, 1640201708691) 130.14 6 [2081, 2083, 2176, 2045, 2046, 2047]\n",
      "deadSpace12 Segment_Type.DEADSPACE (1640201899707, 1640201968335) 68.628 3 [2859, 2876, 2877]\n",
      "deadSpace13 Segment_Type.DEADSPACE (1640202073587, 1641502449931) 1300376.344 3 [3040, 3049, 3061]\n",
      "deadSpace14 Segment_Type.DEADSPACE (1641502510070, 1641584293776) 81783.706 3 [3018, 4019, 4020]\n",
      "deadSpace15 Segment_Type.DEADSPACE (1641584454611, 1641584584359) 129.748 2 [3969, 3519]\n",
      "deadSpace16 Segment_Type.DEADSPACE (1641584657254, 1641584742169) 84.915 2 [4055, 4072]\n",
      "deadSpace17 Segment_Type.DEADSPACE (1641584821749, 1641585078332) 256.583 2 [3315, 3316]\n",
      "deadSpace18 Segment_Type.DEADSPACE (1641585114110, 1641585228031) 113.921 2 [3739, 3745]\n",
      "deadSpace19 Segment_Type.DEADSPACE (1641585237896, 1641585458459) 220.563 2 [3580, 3408]\n",
      "deadSpace20 Segment_Type.DEADSPACE (1641585467013, 1641846627837) 261160.824 3 [3582, 7240, 7242]\n",
      "deadSpace21 Segment_Type.DEADSPACE (1641846637675, 1641849234850) 2597.175 2 [5053, 5054]\n",
      "deadSpace22 Segment_Type.DEADSPACE (1641849676536, 1641910810485) 61133.949 2 [7238, 7263]\n",
      "deadSpace23 Segment_Type.DEADSPACE (1641910811783, 1641961009794) 50198.011 2 [7262, 7282]\n",
      "deadSpace24 Segment_Type.DEADSPACE (1641961062271, 1641963232792) 2170.521 4 [7281, 7284, 7285, 7286]\n",
      "deadSpace25 Segment_Type.DEADSPACE (1641963235873, 1642004991756) 41755.883 4 [7279, 7287, 7906, 7907]\n",
      "deadSpace26 Segment_Type.DEADSPACE (1642005017893, 1642005128878) 110.985 2 [7680, 7709]\n",
      "deadSpace27 Segment_Type.DEADSPACE (1642005129089, 1642005196721) 67.632 2 [7708, 7691]\n",
      "deadSpace28 Segment_Type.DEADSPACE (1642005199678, 1642013738275) 8538.597 3 [7747, 7912, 7913]\n",
      "deadSpace29 Segment_Type.DEADSPACE (1642013783536, 1642013854497) 70.961 2 [7335, 7336]\n",
      "deadSpace30 Segment_Type.DEADSPACE (1642013961974, 1642014461416) 499.442 2 [8147, 8432]\n",
      "deadSpace31 Segment_Type.DEADSPACE (1642014578838, 1642014670475) 91.637 2 [8738, 8379]\n",
      "deadSpace32 Segment_Type.DEADSPACE (1642014723082, 1642015133292) 410.21 2 [8794, 8731]\n",
      "deadSpace33 Segment_Type.DEADSPACE (1642015161819, 1642015236013) 74.194 2 [8577, 8618]\n",
      "deadSpace34 Segment_Type.DEADSPACE (1642015271091, 1642015659247) 388.156 2 [8682, 8678]\n",
      "deadSpace35 Segment_Type.DEADSPACE (1642015701502, 1642015925856) 224.354 2 [8690, 8712]\n",
      "deadSpace36 Segment_Type.DEADSPACE (1642015928230, 1642016248803) 320.573 2 [8730, 8802]\n",
      "deadSpace37 Segment_Type.DEADSPACE (1642016278737, 1642018691736) 2412.999 2 [8956, 8909]\n",
      "deadSpace38 Segment_Type.DEADSPACE (1642018770931, 1642561099479) 542328.548 2 [8938, 9020]\n",
      "deadSpace39 Segment_Type.DEADSPACE (1642561100398, 1642561241813) 141.415 2 [9072, 9108]\n",
      "deadSpace40 Segment_Type.DEADSPACE (1642561252257, 1642561320627) 68.37 2 [9070, 9124]\n",
      "deadSpace41 Segment_Type.DEADSPACE (1642561588507, 1642561806420) 217.913 2 [9469, 9470]\n",
      "deadSpace42 Segment_Type.DEADSPACE (1642561840009, 1642561903885) 63.876 2 [9691, 9755]\n",
      "deadSpace43 Segment_Type.DEADSPACE (1642561989927, 1642562053670) 63.743 2 [10005, 10016]\n",
      "deadSpace44 Segment_Type.DEADSPACE (1642562185295, 1642562247581) 62.286 2 [10172, 10272]\n",
      "deadSpace45 Segment_Type.DEADSPACE (1642562253855, 1642562316596) 62.741 2 [10229, 10230]\n",
      "deadSpace46 Segment_Type.DEADSPACE (1642562433438, 1642562501117) 67.679 2 [10435, 10444]\n",
      "deadSpace47 Segment_Type.DEADSPACE (1642562644232, 1642563245456) 601.224 2 [10647, 10660]\n",
      "deadSpace48 Segment_Type.DEADSPACE (1642563558577, 1642568294888) 4736.311 4 [11645, 11738, 11739, 11740]\n"
     ]
    }
   ],
   "source": [
    "deadSpaceSegments = distill.detect_deadspace(sorted_data_paths, 60, 0, 0)\n",
    "for counter, d in enumerate(deadSpaceSegments.values(), start=1):\n",
    "    d.segment_name = str(\"deadSpace\" + str(counter))\n",
    "    d.segment_length_sec = (d.start_end_val[1] - d.start_end_val[0])/1000\n",
    "    print(d.segment_name, d.segment_type, d.start_end_val, d.segment_length_sec, d.num_logs, d.uids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946342d",
   "metadata": {},
   "source": [
    "Seems like deadspace is everywhere; could be that what we thought might be deadspace is really normal use. We can quickly regenerate segments with modified time parameters (real deadspace is a longer absence of behavior):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc130a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadSpace1 Segment_Type.DEADSPACE (1640029869288, 1640030063271) 193.983 4 [350, 301, 346, 347]\n",
      "deadSpace2 Segment_Type.DEADSPACE (1640030219069, 1640098958897) 68739.828 2 [840, 924]\n",
      "deadSpace3 Segment_Type.DEADSPACE (1640098969598, 1640099715182) 745.584 2 [991, 990]\n",
      "deadSpace4 Segment_Type.DEADSPACE (1640099716927, 1640118186776) 18469.849 3 [1007, 674, 1126]\n",
      "deadSpace5 Segment_Type.DEADSPACE (1640118296632, 1640182567282) 64270.65 6 [782, 981, 1121, 1222, 1227, 1241]\n",
      "deadSpace6 Segment_Type.DEADSPACE (1640182573419, 1640201030250) 18456.831 3 [1231, 1426, 1589]\n",
      "deadSpace7 Segment_Type.DEADSPACE (1640202073587, 1641502449931) 1300376.344 3 [3040, 3049, 3061]\n",
      "deadSpace8 Segment_Type.DEADSPACE (1641502510070, 1641584293776) 81783.706 3 [3018, 4019, 4020]\n",
      "deadSpace9 Segment_Type.DEADSPACE (1641584821749, 1641585078332) 256.583 2 [3315, 3316]\n",
      "deadSpace10 Segment_Type.DEADSPACE (1641585237896, 1641585458459) 220.563 2 [3580, 3408]\n",
      "deadSpace11 Segment_Type.DEADSPACE (1641585467013, 1641846627837) 261160.824 3 [3582, 7240, 7242]\n",
      "deadSpace12 Segment_Type.DEADSPACE (1641846637675, 1641849234850) 2597.175 2 [5053, 5054]\n",
      "deadSpace13 Segment_Type.DEADSPACE (1641849676536, 1641910810485) 61133.949 2 [7238, 7263]\n",
      "deadSpace14 Segment_Type.DEADSPACE (1641910811783, 1641961009794) 50198.011 2 [7262, 7282]\n",
      "deadSpace15 Segment_Type.DEADSPACE (1641961062271, 1641963232792) 2170.521 4 [7281, 7284, 7285, 7286]\n",
      "deadSpace16 Segment_Type.DEADSPACE (1641963235873, 1642004991756) 41755.883 4 [7279, 7287, 7906, 7907]\n",
      "deadSpace17 Segment_Type.DEADSPACE (1642005199678, 1642013738275) 8538.597 3 [7747, 7912, 7913]\n",
      "deadSpace18 Segment_Type.DEADSPACE (1642013961974, 1642014461416) 499.442 2 [8147, 8432]\n",
      "deadSpace19 Segment_Type.DEADSPACE (1642014723082, 1642015133292) 410.21 2 [8794, 8731]\n",
      "deadSpace20 Segment_Type.DEADSPACE (1642015271091, 1642015659247) 388.156 2 [8682, 8678]\n",
      "deadSpace21 Segment_Type.DEADSPACE (1642015701502, 1642015925856) 224.354 2 [8690, 8712]\n",
      "deadSpace22 Segment_Type.DEADSPACE (1642015928230, 1642016248803) 320.573 2 [8730, 8802]\n",
      "deadSpace23 Segment_Type.DEADSPACE (1642016278737, 1642018691736) 2412.999 2 [8956, 8909]\n",
      "deadSpace24 Segment_Type.DEADSPACE (1642018770931, 1642561099479) 542328.548 2 [8938, 9020]\n",
      "deadSpace25 Segment_Type.DEADSPACE (1642561588507, 1642561806420) 217.913 2 [9469, 9470]\n",
      "deadSpace26 Segment_Type.DEADSPACE (1642562644232, 1642563245456) 601.224 2 [10647, 10660]\n",
      "deadSpace27 Segment_Type.DEADSPACE (1642563558577, 1642568294888) 4736.311 4 [11645, 11738, 11739, 11740]\n"
     ]
    }
   ],
   "source": [
    "deadSpaceSegments = distill.detect_deadspace(sorted_data_paths, 180, 0, 0)\n",
    "for counter, d in enumerate(deadSpaceSegments.values(), start=1):\n",
    "    d.segment_name = str(\"deadSpace\" + str(counter))\n",
    "    d.segment_length_sec = (d.start_end_val[1] - d.start_end_val[0])/1000\n",
    "    print(d.segment_name, d.segment_type, d.start_end_val, d.segment_length_sec, d.num_logs, d.uids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f593d800",
   "metadata": {},
   "source": [
    "Add the deadspace segments that seem more reasonable to the Master Dictionary of segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "superSegments.update(deadSpaceSegments)\n",
    "for d in superSegments.values():\n",
    "    print(d.segment_name, d.segment_type, d.start_end_val, d.num_logs, d.uids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf72eb2",
   "metadata": {},
   "source": [
    "### Simple Segments - Toggles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaca0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "toggleEle = ['button.ant-btn superset-button css-1mljg09', 'div#chart-id-515.filter_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapSegments = distill.generate_segments(sorted_data_paths,'path',['div.superset-legacy-chart-world-map','window'],0,30)\n",
    "for counter, d in enumerate(mapSegments.values(), start=1):\n",
    "    d.segment_name = str(\"map_\" + str(counter))\n",
    "    print(d.segment_name, d.start_end_val, d.num_logs, d.uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Python code to merge dict using update() method\n",
    "def Merge(dict1, dict2):\n",
    "    return(dict2.update(dict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapSegments_list = []\n",
    "mapSegment_times = []\n",
    "for d in mapSegments.values():\n",
    "    if d.num_logs > 50:\n",
    "        mapSegments_list.append(d.segment_name)\n",
    "        mapSegment_times.append(d.start_end_val)\n",
    "        print(d.segment_name, d.start_end_val, d.num_logs, d.uids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322fb822",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterDataBy = ['click']\n",
    "sorted_data_paths_clicks = {k:v for k, v in sorted_data_paths.items() if any(item in values for item in v.values())}\n",
    "len(sorted_data_paths_clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd046dbe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapSegments_data = distill.write_segment(sorted_data_paths_clicks, mapSegments_list, mapSegment_times)\n",
    "list(mapSegments_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26915660",
   "metadata": {},
   "source": [
    "## Graphs and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17476fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_map_1 = distill.pairwiseSeq(['|'.join(log['path']) for log in mapSegments_data['map_1'].values()])\n",
    "edges_list_map_1 = list(edges_map_1)\n",
    "edges_map_2 = distill.pairwiseSeq(['|'.join(log['path']) for log in mapSegments_data['map_2'].values()])\n",
    "edges_list_map_2 = list(edges_map_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_map_1 = set(['|'.join(log['path']) for log in mapSegments_data['map_1'].values()])\n",
    "nodes_list_map_1 = list(nodes_map_1)\n",
    "nodes_map_2 = set(['|'.join(log['path']) for log in mapSegments_data['map_2'].values()])\n",
    "nodes_list_map_2 = list(nodes_map_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1140db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_map1 = distill.createDiGraph(nodes_list_map_1, edges_list_map_1, drop_recursions = False)\n",
    "G_map2 = distill.createDiGraph(nodes_list_map_2, edges_list_map_2, drop_recursions = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_map1, with_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81165c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nx.draw(G_map2, with_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839167fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_node_connectivity(G_map2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db537c67",
   "metadata": {},
   "source": [
    "## Exploratory Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7231ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "distill.sankey(edges_map_2,[nodes_list_map_2[item].split(\"|\")[0] for item in range(len(nodes_list_map_2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb3d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "distill.funnel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b105f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b4d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clickRate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06bf50a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90badd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list_temp = []\n",
    "for row in edges_segmentN:\n",
    "    if row[0] != row[1]: \n",
    "        edge_list_temp.append(row)\n",
    "edge_list = edge_list_temp\n",
    "\n",
    "edge_list_counter = Counter(edge_list)\n",
    "\n",
    "source_list = [i[0] for i in edge_list_counter.keys()]\n",
    "target_list = [i[1] for i in edge_list_counter.keys()]\n",
    "value_list = [i for i in edge_list_counter.values()]\n",
    "\n",
    "nodes = []\n",
    "for row in edge_list:\n",
    "    for col in row:\n",
    "        if col not in nodes:\n",
    "            nodes.append(col)           \n",
    "            \n",
    "sources = []\n",
    "for i in source_list:\n",
    "       sources.append(nodes.index(i))\n",
    "targets = []\n",
    "for i in target_list:\n",
    "        targets.append(nodes.index(i))\n",
    "values = value_list\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      label = [nodes[item].split(\"|\")[0] for item in range(len(nodes))],\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = sources,\n",
    "      target = targets,\n",
    "      value = values\n",
    "  ))])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd03731",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [hashlib.md5('_'.join(log['path']).encode('utf-8')).digest() for log in finalSegments['...'].values()]\n",
    "y = [hashlib.md5('_'.join(log['path']).encode('utf-8')).digest() for log in finalSegments['...'].values()]\n",
    "set(x) & set (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf9bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['_'.join(log['path']) for log in finalSegments['...'].values()]\n",
    "y = ['_'.join(log['path']) for log in finalSegments['...'].values()]\n",
    "set(x) & set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1e095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.graph_edit_distance(G_segmentN, G_segmentN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f79c272",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in nx.optimize_graph_edit_distance(G_segmentN, G_segmentN):\n",
    "    minv = v\n",
    "minv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
